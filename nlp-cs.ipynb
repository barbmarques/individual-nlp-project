{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import env\n",
    "import acquire, prepare\n",
    "import requests as req\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#acquire github data on repos referencing 470 cyber security repositories\n",
    "# scrape = acquire.scrape_github_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(scrape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(scrape)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = df.to_csv('repo_readmes.csv')\n",
    "df = pd.read_csv('repo_readmes.csv', usecols=['repo','language','readme_contents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 470 entries, 0 to 469\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   repo             470 non-null    object\n",
      " 1   language         305 non-null    object\n",
      " 2   readme_contents  395 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 11.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 254 entries, 5 to 469\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   repo             254 non-null    object\n",
      " 1   language         254 non-null    object\n",
      " 2   readme_contents  254 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df[df.language.notnull()]\n",
    "df = df[df.readme_contents.notnull()]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "Python              80\n",
       "Jupyter Notebook    36\n",
       "HTML                26\n",
       "Java                19\n",
       "Shell               17\n",
       "JavaScript          14\n",
       "CSS                 11\n",
       "C                    6\n",
       "C++                  6\n",
       "PHP                  5\n",
       "C#                   5\n",
       "TeX                  4\n",
       "PowerShell           3\n",
       "Dart                 2\n",
       "R                    2\n",
       "Ruby                 2\n",
       "Dockerfile           2\n",
       "Pug                  2\n",
       "Batchfile            1\n",
       "Go                   1\n",
       "Verilog              1\n",
       "HCL                  1\n",
       "Haxe                 1\n",
       "TypeScript           1\n",
       "Kotlin               1\n",
       "Objective-C          1\n",
       "Ren'Py               1\n",
       "SCSS                 1\n",
       "Scala                1\n",
       "Assembly             1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropped languages with only 1 observation\n",
    "# Dropped 165 nulls in language\n",
    "df.value_counts('language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit dataframe to the top 6 languages\n",
    "top_6_languages = df.language.value_counts().index[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DerekBabb/CyberSecurity</td>\n",
       "      <td>Java</td>\n",
       "      <td># Cyber Security\\n### A curriculum for a high ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PacktPublishing/Machine-Learning-for-Cybersecu...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># Machine Learning for Cybersecurity Cookbook ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llSourcell/Build-a-Cybersecurity-Startup</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># Overview\\n\\nThis is the code for [this](http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>scusec/Data-Mining-for-Cybersecurity</td>\n",
       "      <td>HTML</td>\n",
       "      <td># Data-Mining-for-Cybersecurity\\n\\n本项目主要是课程《Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>guidesmiths/cybersecurity-handbook</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># Cybersecurity handbook\\n\\n![Cover image](pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>jonathan6661/P1sty</td>\n",
       "      <td>Python</td>\n",
       "      <td># P1sty\\n\\n&lt;p align=\"center\"&gt;\\n&lt;img src=\"https...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Patrowl/PatrowlHears</td>\n",
       "      <td>Python</td>\n",
       "      <td>![](https://github.com/Patrowl/PatrowlDocs/blo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>tropicoo/zoneh</td>\n",
       "      <td>Python</td>\n",
       "      <td># zoneh\\nZone-H cybercrime archive monitoring ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>diogo-fernan/domfind</td>\n",
       "      <td>Python</td>\n",
       "      <td># *domfind*\\n\\n*domfind* is a Python 3.6.x uti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>joaovitorbf/nwam</td>\n",
       "      <td>Python</td>\n",
       "      <td>_   ___          __     __  __ \\n     | ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  repo          language  \\\n",
       "5                              DerekBabb/CyberSecurity              Java   \n",
       "7    PacktPublishing/Machine-Learning-for-Cybersecu...  Jupyter Notebook   \n",
       "8             llSourcell/Build-a-Cybersecurity-Startup        JavaScript   \n",
       "15                scusec/Data-Mining-for-Cybersecurity              HTML   \n",
       "16                  guidesmiths/cybersecurity-handbook        JavaScript   \n",
       "..                                                 ...               ...   \n",
       "461                                 jonathan6661/P1sty            Python   \n",
       "464                               Patrowl/PatrowlHears            Python   \n",
       "466                                     tropicoo/zoneh            Python   \n",
       "467                               diogo-fernan/domfind            Python   \n",
       "468                                   joaovitorbf/nwam            Python   \n",
       "\n",
       "                                       readme_contents  \n",
       "5    # Cyber Security\\n### A curriculum for a high ...  \n",
       "7    # Machine Learning for Cybersecurity Cookbook ...  \n",
       "8    # Overview\\n\\nThis is the code for [this](http...  \n",
       "15   # Data-Mining-for-Cybersecurity\\n\\n本项目主要是课程《Da...  \n",
       "16   # Cybersecurity handbook\\n\\n![Cover image](pub...  \n",
       "..                                                 ...  \n",
       "461  # P1sty\\n\\n<p align=\"center\">\\n<img src=\"https...  \n",
       "464  ![](https://github.com/Patrowl/PatrowlDocs/blo...  \n",
       "466  # zoneh\\nZone-H cybercrime archive monitoring ...  \n",
       "467  # *domfind*\\n\\n*domfind* is a Python 3.6.x uti...  \n",
       "468        _   ___          __     __  __ \\n     | ...  \n",
       "\n",
       "[192 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.language.isin(top_6_languages)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prepare the data by applying the clean function\n",
    "# df.readme_contents = df.readme_contents.apply(prepare.clean)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    'A simple function to cleanup text data'\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "    return [wnl.lemmatize(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DerekBabb/CyberSecurity</td>\n",
       "      <td>Java</td>\n",
       "      <td># Cyber Security\\n### A curriculum for a high ...</td>\n",
       "      <td>cyber security curriculum high school cyber se...</td>\n",
       "      <td>cyber secur curriculum high school cyber secur...</td>\n",
       "      <td>cyber security curriculum high school cyber se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PacktPublishing/Machine-Learning-for-Cybersecu...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># Machine Learning for Cybersecurity Cookbook ...</td>\n",
       "      <td>machine learning cybersecurity cookbook hrefht...</td>\n",
       "      <td>machin learn cybersecur cookbook hrefhttpswwwp...</td>\n",
       "      <td>machine learning cybersecurity cookbook hrefht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llSourcell/Build-a-Cybersecurity-Startup</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># Overview\\n\\nThis is the code for [this](http...</td>\n",
       "      <td>overview code thishttpsyoutubebxw8vqxxvqc vide...</td>\n",
       "      <td>overview code thishttpsyoutubebxw8vqxxvqc vide...</td>\n",
       "      <td>overview code thishttpsyoutubebxw8vqxxvqc vide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>scusec/Data-Mining-for-Cybersecurity</td>\n",
       "      <td>HTML</td>\n",
       "      <td># Data-Mining-for-Cybersecurity\\n\\n本项目主要是课程《Da...</td>\n",
       "      <td>dataminingforcybersecurity data mining cyberse...</td>\n",
       "      <td>dataminingforcybersecur data mine cybersecur 2...</td>\n",
       "      <td>dataminingforcybersecurity data mining cyberse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>guidesmiths/cybersecurity-handbook</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># Cybersecurity handbook\\n\\n![Cover image](pub...</td>\n",
       "      <td>cybersecurity handbook cover imagepubliccoverj...</td>\n",
       "      <td>cybersecur handbook cover imagepubliccoverjpg ...</td>\n",
       "      <td>cybersecurity handbook cover imagepubliccoverj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>jonathan6661/P1sty</td>\n",
       "      <td>Python</td>\n",
       "      <td># P1sty\\n\\n&lt;p align=\"center\"&gt;\\n&lt;img src=\"https...</td>\n",
       "      <td>p1sty p aligncenter img srchttpsuserimagesgith...</td>\n",
       "      <td>p1sti p aligncent img srchttpsuserimagesgithub...</td>\n",
       "      <td>p1sty p aligncenter img srchttpsuserimagesgith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Patrowl/PatrowlHears</td>\n",
       "      <td>Python</td>\n",
       "      <td>![](https://github.com/Patrowl/PatrowlDocs/blo...</td>\n",
       "      <td>httpsgithubcompatrowlpatrowldocsblobmasterimag...</td>\n",
       "      <td>httpsgithubcompatrowlpatrowldocsblobmasterimag...</td>\n",
       "      <td>httpsgithubcompatrowlpatrowldocsblobmasterimag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>tropicoo/zoneh</td>\n",
       "      <td>Python</td>\n",
       "      <td># zoneh\\nZone-H cybercrime archive monitoring ...</td>\n",
       "      <td>zoneh zoneh cybercrime archive monitoring tele...</td>\n",
       "      <td>zoneh zoneh cybercrim archiv monitor telegram ...</td>\n",
       "      <td>zoneh zoneh cybercrime archive monitoring tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>diogo-fernan/domfind</td>\n",
       "      <td>Python</td>\n",
       "      <td># *domfind*\\n\\n*domfind* is a Python 3.6.x uti...</td>\n",
       "      <td>domfind domfind python 36x utility tests exist...</td>\n",
       "      <td>domfind domfind python 36x util test exist dom...</td>\n",
       "      <td>domfind domfind python 36x utility test existe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>joaovitorbf/nwam</td>\n",
       "      <td>Python</td>\n",
       "      <td>_   ___          __     __  __ \\n     | ...</td>\n",
       "      <td>netwave admin mapper ' change password tool se...</td>\n",
       "      <td>netwav admin mapper ' chang password tool sear...</td>\n",
       "      <td>netwave admin mapper ' change password tool se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  repo          language  \\\n",
       "5                              DerekBabb/CyberSecurity              Java   \n",
       "7    PacktPublishing/Machine-Learning-for-Cybersecu...  Jupyter Notebook   \n",
       "8             llSourcell/Build-a-Cybersecurity-Startup        JavaScript   \n",
       "15                scusec/Data-Mining-for-Cybersecurity              HTML   \n",
       "16                  guidesmiths/cybersecurity-handbook        JavaScript   \n",
       "..                                                 ...               ...   \n",
       "461                                 jonathan6661/P1sty            Python   \n",
       "464                               Patrowl/PatrowlHears            Python   \n",
       "466                                     tropicoo/zoneh            Python   \n",
       "467                               diogo-fernan/domfind            Python   \n",
       "468                                   joaovitorbf/nwam            Python   \n",
       "\n",
       "                                       readme_contents  \\\n",
       "5    # Cyber Security\\n### A curriculum for a high ...   \n",
       "7    # Machine Learning for Cybersecurity Cookbook ...   \n",
       "8    # Overview\\n\\nThis is the code for [this](http...   \n",
       "15   # Data-Mining-for-Cybersecurity\\n\\n本项目主要是课程《Da...   \n",
       "16   # Cybersecurity handbook\\n\\n![Cover image](pub...   \n",
       "..                                                 ...   \n",
       "461  # P1sty\\n\\n<p align=\"center\">\\n<img src=\"https...   \n",
       "464  ![](https://github.com/Patrowl/PatrowlDocs/blo...   \n",
       "466  # zoneh\\nZone-H cybercrime archive monitoring ...   \n",
       "467  # *domfind*\\n\\n*domfind* is a Python 3.6.x uti...   \n",
       "468        _   ___          __     __  __ \\n     | ...   \n",
       "\n",
       "                                                 clean  \\\n",
       "5    cyber security curriculum high school cyber se...   \n",
       "7    machine learning cybersecurity cookbook hrefht...   \n",
       "8    overview code thishttpsyoutubebxw8vqxxvqc vide...   \n",
       "15   dataminingforcybersecurity data mining cyberse...   \n",
       "16   cybersecurity handbook cover imagepubliccoverj...   \n",
       "..                                                 ...   \n",
       "461  p1sty p aligncenter img srchttpsuserimagesgith...   \n",
       "464  httpsgithubcompatrowlpatrowldocsblobmasterimag...   \n",
       "466  zoneh zoneh cybercrime archive monitoring tele...   \n",
       "467  domfind domfind python 36x utility tests exist...   \n",
       "468  netwave admin mapper ' change password tool se...   \n",
       "\n",
       "                                               stemmed  \\\n",
       "5    cyber secur curriculum high school cyber secur...   \n",
       "7    machin learn cybersecur cookbook hrefhttpswwwp...   \n",
       "8    overview code thishttpsyoutubebxw8vqxxvqc vide...   \n",
       "15   dataminingforcybersecur data mine cybersecur 2...   \n",
       "16   cybersecur handbook cover imagepubliccoverjpg ...   \n",
       "..                                                 ...   \n",
       "461  p1sti p aligncent img srchttpsuserimagesgithub...   \n",
       "464  httpsgithubcompatrowlpatrowldocsblobmasterimag...   \n",
       "466  zoneh zoneh cybercrim archiv monitor telegram ...   \n",
       "467  domfind domfind python 36x util test exist dom...   \n",
       "468  netwav admin mapper ' chang password tool sear...   \n",
       "\n",
       "                                            lemmatized  \n",
       "5    cyber security curriculum high school cyber se...  \n",
       "7    machine learning cybersecurity cookbook hrefht...  \n",
       "8    overview code thishttpsyoutubebxw8vqxxvqc vide...  \n",
       "15   dataminingforcybersecurity data mining cyberse...  \n",
       "16   cybersecurity handbook cover imagepubliccoverj...  \n",
       "..                                                 ...  \n",
       "461  p1sty p aligncenter img srchttpsuserimagesgith...  \n",
       "464  httpsgithubcompatrowlpatrowldocsblobmasterimag...  \n",
       "466  zoneh zoneh cybercrime archive monitoring tele...  \n",
       "467  domfind domfind python 36x utility test existe...  \n",
       "468  netwave admin mapper ' change password tool se...  \n",
       "\n",
       "[192 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "df['clean'] = df['readme_contents'].apply(lambda x: prepare.remove_stopwords(prepare.tokenize(prepare.basic_clean(x))))\n",
    "#stemmed to hold the stemmed version of the cleaned data.\n",
    "df['stemmed'] = df['clean'].apply(lambda x: prepare.stem(x))\n",
    "#lemmatized to hold the lemmatized version of the cleaned data.\n",
    "df['lemmatized'] = df['clean'].apply(lambda x: prepare.lemmatize(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use clean function to create six sets of data: Python, Jupyter Notebook, HTML, Java, Shell, JavaScript and CSS and rejoin lemmatized words to one string\n",
    "python_words = clean(' '.join(df.lemmatized[df.language == 'Python']))\n",
    "jupyter_words = clean(' '.join(df.lemmatized[df.language == 'Jupyter Notebook']))\n",
    "html_words = clean(' '.join(df.lemmatized[df.language == 'HTML']))\n",
    "java_words = clean(' '.join(df.lemmatized[df.language == 'Java']))\n",
    "shell_words = clean(' '.join(df.lemmatized[df.language == 'Shell']))\n",
    "jscript_words = clean(' '.join(df.lemmatized[df.language == 'JavaScript']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pip, install)       20\n",
       "(cyber, security)    13\n",
       "(domain, name)       12\n",
       "(git, clone)         12\n",
       "(aptget, install)    11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding most common bigrams in python words\n",
    "top_10_python_bigrams = (pd.Series(nltk.ngrams(python_words, 2))\n",
    "                      .value_counts()\n",
    "                      .head(10))\n",
    "\n",
    "top_10_python_bigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(machine, learning)    37\n",
       "(window, mac)          16\n",
       "(x, linux)             16\n",
       "(jupyter, notebook)    16\n",
       "(mac, o)               16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding most common bigrams in jupyter words\n",
    "top_10_jupyter_bigrams = (pd.Series(nltk.ngrams(jupyter_words, 2))\n",
    "                      .value_counts()\n",
    "                      .head(10))\n",
    "\n",
    "top_10_jupyter_bigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)                      9\n",
       "(social, engineering)       8\n",
       "(capture, flag)             7\n",
       "(assignment, submission)    5\n",
       "(attack, social)            5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding most common bigrams in html words\n",
    "top_10_html_bigrams = (pd.Series(nltk.ngrams(html_words, 2))\n",
    "                      .value_counts()\n",
    "                      .head(10))\n",
    "\n",
    "top_10_html_bigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(cyber, security)       28\n",
       "(step, reproduce)       21\n",
       "(reproduce, 1)          16\n",
       "(username, password)    12\n",
       "(1, open)               11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding most common bigrams in java words\n",
    "top_10_java_bigrams = (pd.Series(nltk.ngrams(java_words, 2))\n",
    "                      .value_counts()\n",
    "                      .head(10))\n",
    "\n",
    "top_10_java_bigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(elk, server)           8\n",
       "(container, running)    8\n",
       "(running, dvwa)         7\n",
       "(host, container)       6\n",
       "(br, download)          6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding most common bigrams in shell words\n",
    "top_10_shell_bigrams = (pd.Series(nltk.ngrams(shell_words, 2))\n",
    "                      .value_counts()\n",
    "                      .head(10))\n",
    "\n",
    "top_10_shell_bigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sulla, blockchain)    17\n",
       "(che, ci)              16\n",
       "(styleborder, 0h3a)    15\n",
       "(td, styleborder)      15\n",
       "(npm, install)         11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding most common bigrams in jscript words\n",
    "top_10_jscript_bigrams = (pd.Series(nltk.ngrams(jscript_words, 2))\n",
    "                      .value_counts()\n",
    "                      .head(10))\n",
    "\n",
    "top_10_jscript_bigrams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use this split function later to create in-sample and out-of-sample datasets for modeling\n",
    "def split(df, stratify_by=None):\n",
    "    \"\"\"\n",
    "    3 way split for train, validate, and test datasets\n",
    "    To stratify, send in a column name\n",
    "    \"\"\"\n",
    "    train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df[stratify_by])\n",
    "    \n",
    "    train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train[stratify_by])\n",
    "    \n",
    "    return train, validate, test\n",
    "\n",
    "\n",
    "train, validate, test = split(df, 'language')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>chygozprivaterepo/CybersecurityAE1</td>\n",
       "      <td>Java</td>\n",
       "      <td># CybersecurityAE1\\n</td>\n",
       "      <td>cybersecurityae1</td>\n",
       "      <td>cybersecurityae1</td>\n",
       "      <td>cybersecurityae1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>YriyAntonov228/CyberSecurity</td>\n",
       "      <td>Java</td>\n",
       "      <td># CyberSecurity - это электронная проходная\\n#...</td>\n",
       "      <td>cybersecurity java 18 oracle jdk open jdk http...</td>\n",
       "      <td>cybersecur java 18 oracl jdk open jdk httpsdis...</td>\n",
       "      <td>cybersecurity java 18 oracle jdk open jdk http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>levitannin/AI-in-Cybersecurity</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># AI-in-Cybersecurity\\nPrograms worked on in u...</td>\n",
       "      <td>aiincybersecurity programs worked university c...</td>\n",
       "      <td>aiincybersecur program work univers cours arti...</td>\n",
       "      <td>aiincybersecurity program worked university co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>GambuzX/Cybersecurity_Practice</td>\n",
       "      <td>Python</td>\n",
       "      <td># CTF_Practice</td>\n",
       "      <td>ctfpractice</td>\n",
       "      <td>ctfpractic</td>\n",
       "      <td>ctfpractice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Philser/cybersecurity</td>\n",
       "      <td>Python</td>\n",
       "      <td># cybersecurity\\nRepository for everything cyb...</td>\n",
       "      <td>cybersecurity repository everything cybersecurity</td>\n",
       "      <td>cybersecur repositori everyth cybersecur</td>\n",
       "      <td>cybersecurity repository everything cybersecurity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>marianomatelo/MLCybersecurity</td>\n",
       "      <td>Python</td>\n",
       "      <td># MLCybersecurity\\nMachine Learning Cybersecur...</td>\n",
       "      <td>mlcybersecurity machine learning cybersecurity...</td>\n",
       "      <td>mlcybersecur machin learn cybersecur project f...</td>\n",
       "      <td>mlcybersecurity machine learning cybersecurity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>nikomn/cybersecuritybase2021-project1</td>\n",
       "      <td>Python</td>\n",
       "      <td># cybersecuritybase2021-project1\\n\\nCourse pro...</td>\n",
       "      <td>cybersecuritybase2021project1 course project c...</td>\n",
       "      <td>cybersecuritybase2021project1 cours project cy...</td>\n",
       "      <td>cybersecuritybase2021project1 course project c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>KausikN/CyberSecurity</td>\n",
       "      <td>Python</td>\n",
       "      <td># CyberSecurity\\n Cyber Security Codes for Cip...</td>\n",
       "      <td>cybersecurity cyber security codes ciphers enc...</td>\n",
       "      <td>cybersecur cyber secur code cipher encrypt</td>\n",
       "      <td>cybersecurity cyber security code cipher encry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>LucienCastle/CyberSecurity</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># CyberSecurity\\nData encryption algortihms an...</td>\n",
       "      <td>cybersecurity data encryption algortihms ciphers</td>\n",
       "      <td>cybersecur data encrypt algortihm cipher</td>\n",
       "      <td>cybersecurity data encryption algortihms cipher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>pwnorbitals/CybersecurityReinforcementLearning</td>\n",
       "      <td>Python</td>\n",
       "      <td># CybersecurityReinforcementLearning\\nNovel en...</td>\n",
       "      <td>cybersecurityreinforcementlearning novel envir...</td>\n",
       "      <td>cybersecurityreinforcementlearn novel environ ...</td>\n",
       "      <td>cybersecurityreinforcementlearning novel envir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               repo          language  \\\n",
       "384              chygozprivaterepo/CybersecurityAE1              Java   \n",
       "405                    YriyAntonov228/CyberSecurity              Java   \n",
       "286                  levitannin/AI-in-Cybersecurity  Jupyter Notebook   \n",
       "147                  GambuzX/Cybersecurity_Practice            Python   \n",
       "249                           Philser/cybersecurity            Python   \n",
       "..                                              ...               ...   \n",
       "456                   marianomatelo/MLCybersecurity            Python   \n",
       "392           nikomn/cybersecuritybase2021-project1            Python   \n",
       "211                           KausikN/CyberSecurity            Python   \n",
       "425                      LucienCastle/CyberSecurity  Jupyter Notebook   \n",
       "415  pwnorbitals/CybersecurityReinforcementLearning            Python   \n",
       "\n",
       "                                       readme_contents  \\\n",
       "384                               # CybersecurityAE1\\n   \n",
       "405  # CyberSecurity - это электронная проходная\\n#...   \n",
       "286  # AI-in-Cybersecurity\\nPrograms worked on in u...   \n",
       "147                                     # CTF_Practice   \n",
       "249  # cybersecurity\\nRepository for everything cyb...   \n",
       "..                                                 ...   \n",
       "456  # MLCybersecurity\\nMachine Learning Cybersecur...   \n",
       "392  # cybersecuritybase2021-project1\\n\\nCourse pro...   \n",
       "211  # CyberSecurity\\n Cyber Security Codes for Cip...   \n",
       "425  # CyberSecurity\\nData encryption algortihms an...   \n",
       "415  # CybersecurityReinforcementLearning\\nNovel en...   \n",
       "\n",
       "                                                 clean  \\\n",
       "384                                   cybersecurityae1   \n",
       "405  cybersecurity java 18 oracle jdk open jdk http...   \n",
       "286  aiincybersecurity programs worked university c...   \n",
       "147                                        ctfpractice   \n",
       "249  cybersecurity repository everything cybersecurity   \n",
       "..                                                 ...   \n",
       "456  mlcybersecurity machine learning cybersecurity...   \n",
       "392  cybersecuritybase2021project1 course project c...   \n",
       "211  cybersecurity cyber security codes ciphers enc...   \n",
       "425   cybersecurity data encryption algortihms ciphers   \n",
       "415  cybersecurityreinforcementlearning novel envir...   \n",
       "\n",
       "                                               stemmed  \\\n",
       "384                                   cybersecurityae1   \n",
       "405  cybersecur java 18 oracl jdk open jdk httpsdis...   \n",
       "286  aiincybersecur program work univers cours arti...   \n",
       "147                                         ctfpractic   \n",
       "249           cybersecur repositori everyth cybersecur   \n",
       "..                                                 ...   \n",
       "456  mlcybersecur machin learn cybersecur project f...   \n",
       "392  cybersecuritybase2021project1 cours project cy...   \n",
       "211         cybersecur cyber secur code cipher encrypt   \n",
       "425           cybersecur data encrypt algortihm cipher   \n",
       "415  cybersecurityreinforcementlearn novel environ ...   \n",
       "\n",
       "                                            lemmatized  \n",
       "384                                   cybersecurityae1  \n",
       "405  cybersecurity java 18 oracle jdk open jdk http...  \n",
       "286  aiincybersecurity program worked university co...  \n",
       "147                                        ctfpractice  \n",
       "249  cybersecurity repository everything cybersecurity  \n",
       "..                                                 ...  \n",
       "456  mlcybersecurity machine learning cybersecurity...  \n",
       "392  cybersecuritybase2021project1 course project c...  \n",
       "211  cybersecurity cyber security code cipher encry...  \n",
       "425    cybersecurity data encryption algortihms cipher  \n",
       "415  cybersecurityreinforcementlearning novel envir...  \n",
       "\n",
       "[107 rows x 6 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our X variables\n",
    "X_train = train.lemmatized\n",
    "X_validate = validate.lemmatized\n",
    "X_test = test.lemmatized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our y variables\n",
    "y_train = train.language\n",
    "y_validate = validate.language\n",
    "y_test = test.language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframes\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_validate = pd.DataFrame(X_validate)\n",
    "X_test = pd.DataFrame(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = pd.DataFrame(y_train)\n",
    "baseline['baseline'] = 'Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>Java</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Java</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Python</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Python</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Python</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Python</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Python</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>Python</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             language baseline\n",
       "384              Java   Python\n",
       "405              Java   Python\n",
       "286  Jupyter Notebook   Python\n",
       "147            Python   Python\n",
       "249            Python   Python\n",
       "..                ...      ...\n",
       "456            Python   Python\n",
       "392            Python   Python\n",
       "211            Python   Python\n",
       "425  Jupyter Notebook   Python\n",
       "415            Python   Python\n",
       "\n",
       "[107 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4205607476635514"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baselinebaseline accuracy\n",
    "baseline_accuracy = (baseline.language == baseline.baseline).mean()\n",
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tfidf vectorizer object\n",
    "# Step 1, this creates a tf-idf values for each word, for each document\n",
    "# Step 2, encodes these values so that we can use models that only work on numbers, like classifications model\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Fit on the training data\n",
    "tfidf.fit(X_train)\n",
    "\n",
    "# Use the object\n",
    "X_train_vectorized = tfidf.transform(X_train)\n",
    "X_validate_vectorized = tfidf.transform(X_validate)\n",
    "X_test_vectorized = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparse vectors/matrices have tons of zeros\n",
    "X_train_vectorized.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 107]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-4322f8ab0025>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fit the classification model on our vectorized train data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vectorized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1340\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1342\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0m\u001b[1;32m   1343\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 107]"
     ]
    }
   ],
   "source": [
    "# Now that we have a vectorized dataset, we can use our classification tools!\n",
    "lm = LogisticRegression()\n",
    "\n",
    "# Fit the classification model on our vectorized train data\n",
    "lm.fit(X_train_vectorized, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the model\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to predict y given those vectorized inputs of X\n",
    "train['predicted'] = lm.predict(X_train_vectorized)\n",
    "validate[\"predicted\"] = lm.predict(X_validate_vectorized)\n",
    "test['predicted'] = lm.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Accuracy\n",
    "train_accuracy = (train.actual == train.predicted).mean()\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of sample accuracy\n",
    "validate_accuracy = (validate.actual == validate.predicted).mean()\n",
    "validate_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#begin building a dataframe to record accuracy\n",
    "metric_df = pd.DataFrame(data=[{\n",
    "    'model': 'logistic regression', \n",
    "    'baseline_accuracy': round(baseline_accuracy,2),\n",
    "    'train_accuracy': round(train_accuracy, 2),\n",
    "    'validate_accuracy': round(validate_accuracy, 2)}])\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "#Create the model\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "rf.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check feature importance\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_train_pred = rf.predict(X_train_vectorized)\n",
    "y_validate_pred = rf.predict(X_validate_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate the probability\n",
    "y_train_pred_proba = rf.predict_proba(X_train_vectorized)\n",
    "y_validate_pred_proba = rf.predict_proba(X_validate_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train_vectorized, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_accuracy = round(rf.score(X_train_vectorized, y_train),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Less precision than Logistic Regression -- will not run on test!\n",
    "#Check accuracy on validate\n",
    "print('Accuracy of random forest classifier on validate set: {:.2f}'\n",
    "     .format(rf.score(X_validate_vectorized, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_validate_accuracy = round(rf.score(X_validate_vectorized, y_validate),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append dataframe to compare accuracy\n",
    "metric_df = metric_df.append({\n",
    "    'model': 'random_forest', \n",
    "    'train_accuracy': rf_train_accuracy,\n",
    "    'validate_accuracy': rf_validate_accuracy}, ignore_index=True)\n",
    "metric_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "knn.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_train_pred = knn.predict(X_train_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate probability\n",
    "y_train_pred_proba = knn.predict_proba(X_train_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on accuracy\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train_vectorized, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train_accuracy = knn.score(X_train_vectorized, y_train)\n",
    "knn_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_validate_pred = knn.predict(X_validate_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate probability\n",
    "y_validate_pred_proba = knn.predict_proba(X_validate_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on accuracy\n",
    "print('Accuracy of KNN classifier on validate set: {:.2f}'\n",
    "     .format(knn.score(X_validate_vectorized, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_validate_accuracy = round(knn.score(X_validate_vectorized, y_validate),2)\n",
    "knn_validate_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append dataframe to compare accuracy\n",
    "metric_df = metric_df.append({\n",
    "    'model': 'K-Nearest Neighbor', \n",
    "    'train_accuracy': round(knn_train_accuracy,2),\n",
    "    'validate_accuracy': knn_validate_accuracy}, ignore_index=True)\n",
    "metric_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.readme_contents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
