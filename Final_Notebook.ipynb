{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import env\n",
    "import acquire, prepare\n",
    "import requests as req\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#acquire github data on repos referencing 470 cyber security repositories\n",
    "# scrape = acquire.scrape_github_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(scrape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(scrape)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = df.to_csv('repo_readmes.csv')\n",
    "df = pd.read_csv('repo_readmes.csv', usecols=['repo','language','readme_contents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 470 entries, 0 to 469\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   repo             470 non-null    object\n",
      " 1   language         305 non-null    object\n",
      " 2   readme_contents  395 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 11.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 254 entries, 5 to 469\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   repo             254 non-null    object\n",
      " 1   language         254 non-null    object\n",
      " 2   readme_contents  254 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df[df.language.notnull()]\n",
    "df = df[df.readme_contents.notnull()]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "Python              80\n",
       "Jupyter Notebook    36\n",
       "HTML                26\n",
       "Java                19\n",
       "Shell               17\n",
       "JavaScript          14\n",
       "CSS                 11\n",
       "C                    6\n",
       "C++                  6\n",
       "PHP                  5\n",
       "C#                   5\n",
       "TeX                  4\n",
       "PowerShell           3\n",
       "Dart                 2\n",
       "R                    2\n",
       "Ruby                 2\n",
       "Dockerfile           2\n",
       "Pug                  2\n",
       "Batchfile            1\n",
       "Go                   1\n",
       "Verilog              1\n",
       "HCL                  1\n",
       "Haxe                 1\n",
       "TypeScript           1\n",
       "Kotlin               1\n",
       "Objective-C          1\n",
       "Ren'Py               1\n",
       "SCSS                 1\n",
       "Scala                1\n",
       "Assembly             1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropped languages with only 1 observation\n",
    "# Dropped 165 nulls in language\n",
    "df.value_counts('language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit dataframe to the top 6 languages\n",
    "top_6_languages = df.language.value_counts().index[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DerekBabb/CyberSecurity</td>\n",
       "      <td>Java</td>\n",
       "      <td># Cyber Security\\n### A curriculum for a high ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PacktPublishing/Machine-Learning-for-Cybersecu...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># Machine Learning for Cybersecurity Cookbook ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llSourcell/Build-a-Cybersecurity-Startup</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># Overview\\n\\nThis is the code for [this](http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>scusec/Data-Mining-for-Cybersecurity</td>\n",
       "      <td>HTML</td>\n",
       "      <td># Data-Mining-for-Cybersecurity\\n\\n本项目主要是课程《Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>guidesmiths/cybersecurity-handbook</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># Cybersecurity handbook\\n\\n![Cover image](pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>jonathan6661/P1sty</td>\n",
       "      <td>Python</td>\n",
       "      <td># P1sty\\n\\n&lt;p align=\"center\"&gt;\\n&lt;img src=\"https...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Patrowl/PatrowlHears</td>\n",
       "      <td>Python</td>\n",
       "      <td>![](https://github.com/Patrowl/PatrowlDocs/blo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>tropicoo/zoneh</td>\n",
       "      <td>Python</td>\n",
       "      <td># zoneh\\nZone-H cybercrime archive monitoring ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>diogo-fernan/domfind</td>\n",
       "      <td>Python</td>\n",
       "      <td># *domfind*\\n\\n*domfind* is a Python 3.6.x uti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>joaovitorbf/nwam</td>\n",
       "      <td>Python</td>\n",
       "      <td>_   ___          __     __  __ \\n     | ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  repo          language  \\\n",
       "5                              DerekBabb/CyberSecurity              Java   \n",
       "7    PacktPublishing/Machine-Learning-for-Cybersecu...  Jupyter Notebook   \n",
       "8             llSourcell/Build-a-Cybersecurity-Startup        JavaScript   \n",
       "15                scusec/Data-Mining-for-Cybersecurity              HTML   \n",
       "16                  guidesmiths/cybersecurity-handbook        JavaScript   \n",
       "..                                                 ...               ...   \n",
       "461                                 jonathan6661/P1sty            Python   \n",
       "464                               Patrowl/PatrowlHears            Python   \n",
       "466                                     tropicoo/zoneh            Python   \n",
       "467                               diogo-fernan/domfind            Python   \n",
       "468                                   joaovitorbf/nwam            Python   \n",
       "\n",
       "                                       readme_contents  \n",
       "5    # Cyber Security\\n### A curriculum for a high ...  \n",
       "7    # Machine Learning for Cybersecurity Cookbook ...  \n",
       "8    # Overview\\n\\nThis is the code for [this](http...  \n",
       "15   # Data-Mining-for-Cybersecurity\\n\\n本项目主要是课程《Da...  \n",
       "16   # Cybersecurity handbook\\n\\n![Cover image](pub...  \n",
       "..                                                 ...  \n",
       "461  # P1sty\\n\\n<p align=\"center\">\\n<img src=\"https...  \n",
       "464  ![](https://github.com/Patrowl/PatrowlDocs/blo...  \n",
       "466  # zoneh\\nZone-H cybercrime archive monitoring ...  \n",
       "467  # *domfind*\\n\\n*domfind* is a Python 3.6.x uti...  \n",
       "468        _   ___          __     __  __ \\n     | ...  \n",
       "\n",
       "[192 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.language.isin(top_6_languages)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prepare the data by applying the clean function\n",
    "# df.readme_contents = df.readme_contents.apply(prepare.clean)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    'A simple function to cleanup text data'\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "    return [wnl.lemmatize(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DerekBabb/CyberSecurity</td>\n",
       "      <td>Java</td>\n",
       "      <td># Cyber Security\\n### A curriculum for a high ...</td>\n",
       "      <td>cyber security curriculum high school cyber se...</td>\n",
       "      <td>cyber secur curriculum high school cyber secur...</td>\n",
       "      <td>cyber security curriculum high school cyber se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PacktPublishing/Machine-Learning-for-Cybersecu...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># Machine Learning for Cybersecurity Cookbook ...</td>\n",
       "      <td>machine learning cybersecurity cookbook hrefht...</td>\n",
       "      <td>machin learn cybersecur cookbook hrefhttpswwwp...</td>\n",
       "      <td>machine learning cybersecurity cookbook hrefht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llSourcell/Build-a-Cybersecurity-Startup</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># Overview\\n\\nThis is the code for [this](http...</td>\n",
       "      <td>overview code thishttpsyoutubebxw8vqxxvqc vide...</td>\n",
       "      <td>overview code thishttpsyoutubebxw8vqxxvqc vide...</td>\n",
       "      <td>overview code thishttpsyoutubebxw8vqxxvqc vide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>scusec/Data-Mining-for-Cybersecurity</td>\n",
       "      <td>HTML</td>\n",
       "      <td># Data-Mining-for-Cybersecurity\\n\\n本项目主要是课程《Da...</td>\n",
       "      <td>dataminingforcybersecurity data mining cyberse...</td>\n",
       "      <td>dataminingforcybersecur data mine cybersecur 2...</td>\n",
       "      <td>dataminingforcybersecurity data mining cyberse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>guidesmiths/cybersecurity-handbook</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># Cybersecurity handbook\\n\\n![Cover image](pub...</td>\n",
       "      <td>cybersecurity handbook cover imagepubliccoverj...</td>\n",
       "      <td>cybersecur handbook cover imagepubliccoverjpg ...</td>\n",
       "      <td>cybersecurity handbook cover imagepubliccoverj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>jonathan6661/P1sty</td>\n",
       "      <td>Python</td>\n",
       "      <td># P1sty\\n\\n&lt;p align=\"center\"&gt;\\n&lt;img src=\"https...</td>\n",
       "      <td>p1sty p aligncenter img srchttpsuserimagesgith...</td>\n",
       "      <td>p1sti p aligncent img srchttpsuserimagesgithub...</td>\n",
       "      <td>p1sty p aligncenter img srchttpsuserimagesgith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Patrowl/PatrowlHears</td>\n",
       "      <td>Python</td>\n",
       "      <td>![](https://github.com/Patrowl/PatrowlDocs/blo...</td>\n",
       "      <td>httpsgithubcompatrowlpatrowldocsblobmasterimag...</td>\n",
       "      <td>httpsgithubcompatrowlpatrowldocsblobmasterimag...</td>\n",
       "      <td>httpsgithubcompatrowlpatrowldocsblobmasterimag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>tropicoo/zoneh</td>\n",
       "      <td>Python</td>\n",
       "      <td># zoneh\\nZone-H cybercrime archive monitoring ...</td>\n",
       "      <td>zoneh zoneh cybercrime archive monitoring tele...</td>\n",
       "      <td>zoneh zoneh cybercrim archiv monitor telegram ...</td>\n",
       "      <td>zoneh zoneh cybercrime archive monitoring tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>diogo-fernan/domfind</td>\n",
       "      <td>Python</td>\n",
       "      <td># *domfind*\\n\\n*domfind* is a Python 3.6.x uti...</td>\n",
       "      <td>domfind domfind python 36x utility tests exist...</td>\n",
       "      <td>domfind domfind python 36x util test exist dom...</td>\n",
       "      <td>domfind domfind python 36x utility test existe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>joaovitorbf/nwam</td>\n",
       "      <td>Python</td>\n",
       "      <td>_   ___          __     __  __ \\n     | ...</td>\n",
       "      <td>netwave admin mapper ' change password tool se...</td>\n",
       "      <td>netwav admin mapper ' chang password tool sear...</td>\n",
       "      <td>netwave admin mapper ' change password tool se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  repo          language  \\\n",
       "5                              DerekBabb/CyberSecurity              Java   \n",
       "7    PacktPublishing/Machine-Learning-for-Cybersecu...  Jupyter Notebook   \n",
       "8             llSourcell/Build-a-Cybersecurity-Startup        JavaScript   \n",
       "15                scusec/Data-Mining-for-Cybersecurity              HTML   \n",
       "16                  guidesmiths/cybersecurity-handbook        JavaScript   \n",
       "..                                                 ...               ...   \n",
       "461                                 jonathan6661/P1sty            Python   \n",
       "464                               Patrowl/PatrowlHears            Python   \n",
       "466                                     tropicoo/zoneh            Python   \n",
       "467                               diogo-fernan/domfind            Python   \n",
       "468                                   joaovitorbf/nwam            Python   \n",
       "\n",
       "                                       readme_contents  \\\n",
       "5    # Cyber Security\\n### A curriculum for a high ...   \n",
       "7    # Machine Learning for Cybersecurity Cookbook ...   \n",
       "8    # Overview\\n\\nThis is the code for [this](http...   \n",
       "15   # Data-Mining-for-Cybersecurity\\n\\n本项目主要是课程《Da...   \n",
       "16   # Cybersecurity handbook\\n\\n![Cover image](pub...   \n",
       "..                                                 ...   \n",
       "461  # P1sty\\n\\n<p align=\"center\">\\n<img src=\"https...   \n",
       "464  ![](https://github.com/Patrowl/PatrowlDocs/blo...   \n",
       "466  # zoneh\\nZone-H cybercrime archive monitoring ...   \n",
       "467  # *domfind*\\n\\n*domfind* is a Python 3.6.x uti...   \n",
       "468        _   ___          __     __  __ \\n     | ...   \n",
       "\n",
       "                                                 clean  \\\n",
       "5    cyber security curriculum high school cyber se...   \n",
       "7    machine learning cybersecurity cookbook hrefht...   \n",
       "8    overview code thishttpsyoutubebxw8vqxxvqc vide...   \n",
       "15   dataminingforcybersecurity data mining cyberse...   \n",
       "16   cybersecurity handbook cover imagepubliccoverj...   \n",
       "..                                                 ...   \n",
       "461  p1sty p aligncenter img srchttpsuserimagesgith...   \n",
       "464  httpsgithubcompatrowlpatrowldocsblobmasterimag...   \n",
       "466  zoneh zoneh cybercrime archive monitoring tele...   \n",
       "467  domfind domfind python 36x utility tests exist...   \n",
       "468  netwave admin mapper ' change password tool se...   \n",
       "\n",
       "                                               stemmed  \\\n",
       "5    cyber secur curriculum high school cyber secur...   \n",
       "7    machin learn cybersecur cookbook hrefhttpswwwp...   \n",
       "8    overview code thishttpsyoutubebxw8vqxxvqc vide...   \n",
       "15   dataminingforcybersecur data mine cybersecur 2...   \n",
       "16   cybersecur handbook cover imagepubliccoverjpg ...   \n",
       "..                                                 ...   \n",
       "461  p1sti p aligncent img srchttpsuserimagesgithub...   \n",
       "464  httpsgithubcompatrowlpatrowldocsblobmasterimag...   \n",
       "466  zoneh zoneh cybercrim archiv monitor telegram ...   \n",
       "467  domfind domfind python 36x util test exist dom...   \n",
       "468  netwav admin mapper ' chang password tool sear...   \n",
       "\n",
       "                                            lemmatized  \n",
       "5    cyber security curriculum high school cyber se...  \n",
       "7    machine learning cybersecurity cookbook hrefht...  \n",
       "8    overview code thishttpsyoutubebxw8vqxxvqc vide...  \n",
       "15   dataminingforcybersecurity data mining cyberse...  \n",
       "16   cybersecurity handbook cover imagepubliccoverj...  \n",
       "..                                                 ...  \n",
       "461  p1sty p aligncenter img srchttpsuserimagesgith...  \n",
       "464  httpsgithubcompatrowlpatrowldocsblobmasterimag...  \n",
       "466  zoneh zoneh cybercrime archive monitoring tele...  \n",
       "467  domfind domfind python 36x utility test existe...  \n",
       "468  netwave admin mapper ' change password tool se...  \n",
       "\n",
       "[192 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "df['clean'] = df['readme_contents'].apply(lambda x: prepare.remove_stopwords(prepare.tokenize(prepare.basic_clean(x))))\n",
    "#stemmed to hold the stemmed version of the cleaned data.\n",
    "df['stemmed'] = df['clean'].apply(lambda x: prepare.stem(x))\n",
    "#lemmatized to hold the lemmatized version of the cleaned data.\n",
    "df['lemmatized'] = df['clean'].apply(lambda x: prepare.lemmatize(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use clean function to create six sets of data: Python, Jupyter Notebook, HTML, Java, Shell, JavaScript and CSS and rejoin lemmatized words to one string\n",
    "python_words = clean(' '.join(df.lemmatized[df.language == 'Python']))\n",
    "jupyter_words = clean(' '.join(df.lemmatized[df.language == 'Jupyter Notebook']))\n",
    "html_words = clean(' '.join(df.lemmatized[df.language == 'HTML']))\n",
    "java_words = clean(' '.join(df.lemmatized[df.language == 'Java']))\n",
    "shell_words = clean(' '.join(df.lemmatized[df.language == 'Shell']))\n",
    "jscript_words = clean(' '.join(df.lemmatized[df.language == 'JavaScript']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pip, install)       20\n",
       "(cyber, security)    13\n",
       "(domain, name)       12\n",
       "(git, clone)         12\n",
       "(aptget, install)    11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding most common bigrams in python words\n",
    "top_10_python_bigrams = (pd.Series(nltk.ngrams(python_words, 2))\n",
    "                      .value_counts()\n",
    "                      .head(10))\n",
    "\n",
    "top_10_python_bigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(machine, learning)    37\n",
       "(mac, o)               16\n",
       "(window, mac)          16\n",
       "(x, linux)             16\n",
       "(o, x)                 16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding most common bigrams in jupyter words\n",
    "top_10_jupyter_bigrams = (pd.Series(nltk.ngrams(jupyter_words, 2))\n",
    "                      .value_counts()\n",
    "                      .head(10))\n",
    "\n",
    "top_10_jupyter_bigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)                   9\n",
       "(social, engineering)    8\n",
       "(capture, flag)          7\n",
       "(attack, social)         5\n",
       "(ip, address)            5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding most common bigrams in html words\n",
    "top_10_html_bigrams = (pd.Series(nltk.ngrams(html_words, 2))\n",
    "                      .value_counts()\n",
    "                      .head(10))\n",
    "\n",
    "top_10_html_bigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(cyber, security)       28\n",
       "(step, reproduce)       21\n",
       "(reproduce, 1)          16\n",
       "(username, password)    12\n",
       "(1, open)               11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding most common bigrams in java words\n",
    "top_10_java_bigrams = (pd.Series(nltk.ngrams(java_words, 2))\n",
    "                      .value_counts()\n",
    "                      .head(10))\n",
    "\n",
    "top_10_java_bigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(elk, server)           8\n",
       "(container, running)    8\n",
       "(running, dvwa)         7\n",
       "(br, download)          6\n",
       "(host, container)       6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding most common bigrams in shell words\n",
    "top_10_shell_bigrams = (pd.Series(nltk.ngrams(shell_words, 2))\n",
    "                      .value_counts()\n",
    "                      .head(10))\n",
    "\n",
    "top_10_shell_bigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sulla, blockchain)    17\n",
       "(che, ci)              16\n",
       "(td, styleborder)      15\n",
       "(styleborder, 0h3a)    15\n",
       "(npm, install)         11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding most common bigrams in jscript words\n",
    "top_10_jscript_bigrams = (pd.Series(nltk.ngrams(jscript_words, 2))\n",
    "                      .value_counts()\n",
    "                      .head(10))\n",
    "\n",
    "top_10_jscript_bigrams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish baseline for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = pd.DataFrame(df.language)\n",
    "baseline['baseline'] = 'Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Java</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HTML</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>Python</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Python</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Python</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>Python</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>Python</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             language baseline\n",
       "5                Java   Python\n",
       "7    Jupyter Notebook   Python\n",
       "8          JavaScript   Python\n",
       "15               HTML   Python\n",
       "16         JavaScript   Python\n",
       "..                ...      ...\n",
       "461            Python   Python\n",
       "464            Python   Python\n",
       "466            Python   Python\n",
       "467            Python   Python\n",
       "468            Python   Python\n",
       "\n",
       "[192 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline accuracy is 42%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baselinebaseline accuracy\n",
    "baseline_accuracy = round((baseline.language == baseline.baseline).mean(),2)\n",
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((107, 6), (46, 6), (39, 6))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data for modeling\n",
    "train, validate, test = prepare.split(df, 'language')\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup X-train, validate and test variables\n",
    "X_train = train.lemmatized\n",
    "X_validate = validate.lemmatized\n",
    "X_test = test.lemmatized\n",
    "\n",
    "# setup y-train, validate and test variables\n",
    "y_train = train.language\n",
    "y_validate = validate.language\n",
    "y_test = test.language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((107,), (46,), (39,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_validate.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((107,), (46,), (39,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_validate.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing data before classification modeling\n",
    "- converting text to numerical representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tfidf vectorizer object\n",
    "# Step 1: create tf-idf value for each word, for each lemmatized readme\n",
    "# Step 2: encode these values for use on models that only work on numbers, like classifications model\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Fit on the training data\n",
    "tfidf.fit(X_train)\n",
    "\n",
    "# Use the object\n",
    "X_train_vectorized = tfidf.transform(X_train)\n",
    "X_validate_vectorized = tfidf.transform(X_validate)\n",
    "X_test_vectorized = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create logistic regression object -- to use on vectorized data\n",
    "lm = LogisticRegression()\n",
    "\n",
    "# Fit the classification model on our vectorized train data\n",
    "lm.fit(X_train_vectorized, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframes of actual values\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to predict y given those vectorized inputs of X\n",
    "train['predicted'] = lm.predict(X_train_vectorized)\n",
    "validate[\"predicted\"] = lm.predict(X_validate_vectorized)\n",
    "test['predicted'] = lm.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Accuracy\n",
    "train_accuracy = round((train.actual == train.predicted).mean(),2)\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate Accuracy\n",
    "validate_accuracy = round((validate.actual == validate.predicted).mean(),2)\n",
    "validate_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>baseline_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  baseline_accuracy  train_accuracy  validate_accuracy\n",
       "0  logistic regression               0.42            0.68               0.52"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#begin building a dataframe to record accuracy\n",
    "metric_df = pd.DataFrame(data=[{\n",
    "    'model': 'logistic regression', \n",
    "    'baseline_accuracy': round(baseline_accuracy,2),\n",
    "    'train_accuracy': round(train_accuracy, 2),\n",
    "    'validate_accuracy': round(validate_accuracy, 2)}])\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "#Create the model\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=3, min_samples_leaf=3, random_state=123)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model\n",
    "rf.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#Check feature importance\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_train_pred = rf.predict(X_train_vectorized)\n",
    "y_validate_pred = rf.predict(X_validate_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate the probability\n",
    "y_train_pred_proba = rf.predict_proba(X_train_vectorized)\n",
    "y_validate_pred_proba = rf.predict_proba(X_validate_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.42\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train_vectorized, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_accuracy = round(rf.score(X_train_vectorized, y_train),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0 15  0]\n",
      " [ 0  0  0  0 10  0]\n",
      " [ 0  0  0  0  8  0]\n",
      " [ 0  0  0  0 20  0]\n",
      " [ 0  0  0  0 45  0]\n",
      " [ 0  0  0  0  9  0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "            HTML       0.00      0.00      0.00        15\n",
      "            Java       0.00      0.00      0.00        10\n",
      "      JavaScript       0.00      0.00      0.00         8\n",
      "Jupyter Notebook       0.00      0.00      0.00        20\n",
      "          Python       0.42      1.00      0.59        45\n",
      "           Shell       0.00      0.00      0.00         9\n",
      "\n",
      "        accuracy                           0.42       107\n",
      "       macro avg       0.07      0.17      0.10       107\n",
      "    weighted avg       0.18      0.42      0.25       107\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on validate set: 0.41\n"
     ]
    }
   ],
   "source": [
    "### Less precision than Logistic Regression -- will not run on test!\n",
    "#Check accuracy on validate\n",
    "print('Accuracy of random forest classifier on validate set: {:.2f}'\n",
    "     .format(rf.score(X_validate_vectorized, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_validate_accuracy = round(rf.score(X_validate_vectorized, y_validate),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>baseline_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  baseline_accuracy  train_accuracy  validate_accuracy\n",
       "0  logistic regression               0.42            0.68               0.52\n",
       "1        random_forest               0.42            0.42               0.41\n",
       "2   K-Nearest Neighbor               0.42            0.63               0.43\n",
       "3        random_forest               0.42            0.42               0.41"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#append dataframe to compare accuracy\n",
    "metric_df = metric_df.append({\n",
    "    'model': 'random_forest', \n",
    "    'baseline_accuracy': baseline_accuracy,\n",
    "    'train_accuracy': rf_train_accuracy,\n",
    "    'validate_accuracy': rf_validate_accuracy}, ignore_index=True)\n",
    "metric_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model\n",
    "knn.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_train_pred = knn.predict(X_train_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate probability\n",
    "y_train_pred_proba = knn.predict_proba(X_train_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.63\n"
     ]
    }
   ],
   "source": [
    "#Evaluate on accuracy\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train_vectorized, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6261682242990654"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_train_accuracy = knn.score(X_train_vectorized, y_train)\n",
    "knn_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_validate_pred = knn.predict(X_validate_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate probability\n",
    "y_validate_pred_proba = knn.predict_proba(X_validate_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on validate set: 0.43\n"
     ]
    }
   ],
   "source": [
    "#Evaluate on accuracy\n",
    "print('Accuracy of KNN classifier on validate set: {:.2f}'\n",
    "     .format(knn.score(X_validate_vectorized, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_validate_accuracy = round(knn.score(X_validate_vectorized, y_validate),2)\n",
    "knn_validate_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>baseline_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  baseline_accuracy  train_accuracy  validate_accuracy\n",
       "0  logistic regression               0.42            0.68               0.52\n",
       "1        random_forest               0.42            0.42               0.41\n",
       "2   K-Nearest Neighbor               0.42            0.63               0.43"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#append dataframe to compare accuracy\n",
    "metric_df = metric_df.append({\n",
    "    'model': 'K-Nearest Neighbor', \n",
    "    'baseline_accuracy': baseline_accuracy,\n",
    "    'train_accuracy': round(knn_train_accuracy,2),\n",
    "    'validate_accuracy': knn_validate_accuracy}, ignore_index=True)\n",
    "metric_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_test_pred = knn.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate probability\n",
    "y_test_pred_proba = knn.predict_proba(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on test set: 0.49\n"
     ]
    }
   ],
   "source": [
    "#Evaluate on accuracy\n",
    "print('Accuracy of KNN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test_vectorized, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48717948717948717"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_test_accuracy = knn.score(X_test_vectorized, y_test)\n",
    "knn_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
